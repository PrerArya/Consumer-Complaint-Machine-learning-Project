# -*- coding: utf-8 -*-
"""MachineLearningProj.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b8AFaMUZuH9bVKVJceMMKMt-Rloofl-C

Consumer Complaint Resolution
"""

import pandas as pd
import numpy as np

test = pd.read_csv("Consumer_Complaints_test.csv")

train = pd.read_csv("/content/Consumer_Complaints_train.csv")

test.shape

train.shape

test.info()

train.info()

test.duplicated().sum()

test.isna().sum()

train.isna().sum()

"""Drop coloumns with null values"""

test.drop(["Consumer complaint narrative","Sub-issue","Sub-product","Company public response","ZIP code","Tags","Consumer consent provided?"],axis=1,inplace=True)

test.info()

train.drop(["Consumer complaint narrative","Sub-issue","Sub-product","Company public response","ZIP code","Tags","Consumer consent provided?"],axis=1,inplace=True)

train.info()

train['Date received'].dtype

"""extracting day,month,year from date recieved coloumn"""

train['Date received'] = pd.to_datetime(train['Date received'])

# Extracting day, month, and year into new columns
train['Day'] = train['Date received'].dt.day
train['Month'] = train['Date received'].dt.month
train['Year'] = train['Date received'].dt.year

test['Date received'] = pd.to_datetime(test['Date received'])

# Extracting day, month, and year into new columns
test['Day'] = test['Date received'].dt.day
test['Month'] = test['Date received'].dt.month
test['Year'] = test['Date received'].dt.year

"""Calculatethe Number ofDays the Complaint was with the Companyand create a new field as “Days held”"""

train['Date sent to company'] = pd.to_datetime(train['Date sent to company'])

# Calculate the number of days held
train['Days Held'] = (train['Date sent to company'] - train['Date received']).dt.days

test['Date sent to company'] = pd.to_datetime(test['Date sent to company'])

# Calculate the number of days held
test['Days Held'] = (test['Date sent to company'] - test['Date received']).dt.days

train.drop(["Date received","Date sent to company","Complaint ID"],axis=1,inplace=True)

test.drop(["Date received","Date sent to company","Complaint ID"],axis=1,inplace=True)

mode_state=train["State"].mode()[0]
train['State'].fillna(mode_state, inplace=True)

mode_state=test["State"].mode()[0]
test['State'].fillna(mode_state, inplace=True)

test.isnull().sum()

"""with the help ofthe days we calculated above,create a newfield 'Week_Received'where we calculate the week based on the day of receiving"""

train['Week_Recieved']=(train["Days Held"]/7).round().abs().astype(int)

test['Week_Recieved']=(train["Days Held"]/7).round().abs().astype(int)

train["disputed_cons"]=train["Consumer disputed?"]

"""Plot bar graph of thetotal no of disputes of consumers with the help of seaborn"""

train["Consumer disputed?"].replace({"Yes":1,"No":0},inplace=True)

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming your DataFrame is named train
sns.countplot(x='Consumer disputed?', data=train)
plt.show()

"""Plot bar graph of thetotal no of disputes products-wise with the help ofseaborn"""

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='Product', hue='Consumer disputed?', data=train)
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

"""Plot bar graph ofthe total no of disputes with Top Issues by Highest Disputes, with the help ofseaborn"""

top_issues = train['Issue'].value_counts().nlargest(10).index

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='Issue', hue='Consumer disputed?', data=train[train['Issue'].isin(top_issues)])
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

state_with_max_disputes = train['State'].value_counts().idxmax()

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='State', hue='Consumer disputed?', data=train[train['State'] == state_with_max_disputes])
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='Submitted via', hue='Consumer disputed?', data=train)
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='Company response to consumer', hue='Consumer disputed?', data=train)
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

train['Response Leads to Dispute'] = train['Consumer disputed?'] == 1

plt.figure(figsize=(12, 6))  # Adjust the figure size if needed
sns.countplot(x='Company response to consumer', hue='Response Leads to Dispute', data=train)
plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability
plt.show()

train['Disputes Instead of Timely Response'] = (train['Consumer disputed?'] == 1) & (train['Timely response?'] == 'No')

plt.figure(figsize=(8, 6))  # Adjust the figure size if needed
sns.countplot(x='Disputes Instead of Timely Response', data=train)
plt.xticks([0, 1], ['No', 'Yes'])  # Replace 0 and 1 with corresponding labels
plt.show()

"""Plot bar graph ofthe total no of disputes over Year Wise Complaints
•Plot bar graph ofthe total no of disputes over Year Wise Disputes
•Plot bar graph ofTop Companies with Highest Complaints
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming your DataFrame is named train
plt.figure(figsize=(15, 6))  # Adjust the figure size if needed

# Year Wise Complaints
plt.subplot(1, 3, 1)
sns.countplot(x=train['Year'], data=train)
plt.title('Year Wise Complaints')

# Year Wise Disputes
plt.subplot(1, 3, 2)
sns.countplot(x=train['Year'], hue='Consumer disputed?', data=train)
plt.title('Year Wise Disputes')

# Top Companies with Highest Complaints
plt.subplot(1, 3, 3)
top_companies = train['Company'].value_counts().nlargest(10)
sns.barplot(x=top_companies.values, y=top_companies.index)
plt.title('Top Companies with Highest Complaints')

plt.tight_layout()
plt.show()

"""Converte all negative days held to zero(it is the time taken by the authority that can't be negative)"""

train['Days Held'] = train['Days Held'].apply(lambda x: max(0, x))

train.drop(["Company","State","Days Held","Week_Recieved","Disputes Instead of Timely Response"],axis=1,inplace=True)

train.info()

test.drop(["Company","State"],axis=1,inplace=True)

categorical_columns = ['Product', 'Submitted via', 'Company response to consumer', 'Timely response?']

# Create dummy variables for categorical columns
dummy_df = pd.get_dummies(train[categorical_columns])

# Concatenate dummy variables with the original DataFrame
train = pd.concat([train, dummy_df], axis=1)

# Drop the original categorical columns if needed
train.drop(categorical_columns, axis=1, inplace=True)

ategorical_columns = ['Product', 'Submitted via', 'Company response to consumer', 'Timely response?']

# Create dummy variables for categorical columns
dummy_df = pd.get_dummies(test[categorical_columns])

# Concatenate dummy variables with the original DataFrame
test = pd.concat([test, dummy_df], axis=1)

# Drop the original categorical columns if needed
test.drop(categorical_columns, axis=1, inplace=True)

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import pandas as pd

# Assuming your DataFrame is named train
# Assuming 'Consumer disputed?' is your dependent variable, discard it for feature scaling
X = train.drop(['Consumer disputed?','disputed_cons',"Issue"], axis=1)

# Standardize the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Perform PCA
pca = PCA(n_components=0.8)
X_pca = pca.fit_transform(X_scaled)

# Create a DataFrame with the PCA components
columns_pca = [f'PC{i+1}' for i in range(X_pca.shape[1])]
X_pca_df = pd.DataFrame(data=X_pca, columns=columns_pca)

# Concatenate the PCA components with the original DataFrame (excluding the dependent variable)
train_pca = pd.concat([train[['Consumer disputed?']], X_pca_df], axis=1)

y = train_pca['Consumer disputed?']
X = train_pca.drop(['Consumer disputed?'], axis=1)

y.fillna(y.mode().iloc[0], inplace=True)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_preds_train = lr_model.predict(X_train)
lr_preds_test = lr_model.predict(X_test)

# Decision Tree Classifier
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
dt_preds_train = dt_model.predict(X_train)
dt_preds_test = dt_model.predict(X_test)

# Random Forest Classifier
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_preds_train = rf_model.predict(X_train)
rf_preds_test = rf_model.predict(X_test)

# AdaBoost Classifier
adaboost_model = AdaBoostClassifier()
adaboost_model.fit(X_train, y_train)
adaboost_preds_train = adaboost_model.predict(X_train)
adaboost_preds_test = adaboost_model.predict(X_test)

# AdaBoost Classifier
adaboost_model = AdaBoostClassifier()
adaboost_model.fit(X_train, y_train)
adaboost_preds_train = adaboost_model.predict(X_train)
adaboost_preds_test = adaboost_model.predict(X_test)

knn_model = KNeighborsClassifier()
knn_model.fit(X_train, y_train)
knn_preds_train = knn_model.predict(X_train)
knn_preds_test = knn_model.predict(X_test)

# XGB Classifier
xgb_model = XGBClassifier()
xgb_model.fit(X_train, y_train)
xgb_preds_train = xgb_model.predict(X_train)
xgb_preds_test = xgb_model.predict(X_test)

# Gradient Boosting Classifier
gb_model = GradientBoostingClassifier()
gb_model.fit(X_train, y_train)
gb_preds_train = gb_model.predict(X_train)
gb_preds_test = gb_model.predict(X_test)

# Evaluate the models
def evaluate_model(y_true, y_pred, dataset):
    accuracy = accuracy_score(y_true, y_pred)
    print(f"{dataset} Accuracy: {accuracy:.4f}")

# Display results
evaluate_model(y_train, lr_preds_train, 'Logistic Regression (Train)')
evaluate_model(y_test, lr_preds_test, 'Logistic Regression (Test)')

evaluate_model(y_train, dt_preds_train, 'Decision Tree (Train)')
evaluate_model(y_test, dt_preds_test, 'Decision Tree (Test)')

evaluate_model(y_train, rf_preds_train, 'Random Forest (Train)')
evaluate_model(y_test, rf_preds_test, 'Random Forest (Test)')

evaluate_model(y_train, adaboost_preds_train, 'AdaBoost (Train)')
evaluate_model(y_test, adaboost_preds_test, 'AdaBoost (Test)')

# Corrected line for Gradient Boosting
evaluate_model(y_train, gb_model.predict(X_train), 'Gradient Boosting (Train)')
evaluate_model(y_test, gb_model.predict(X_test), 'Gradient Boosting (Test)')

evaluate_model(y_train, knn_preds_train, 'KNeighbors (Train)')
evaluate_model(y_test, knn_preds_test, 'KNeighbors (Test)')

evaluate_model(y_train, xgb_preds_train, 'XGB (Train)')
evaluate_model(y_test, xgb_preds_test, 'XGB (Test)')

test.drop("Issue",axis=1,inplace=True)

X_test_scaled = scaler.fit_transform(test)

# Apply PCA using the same number of components as used in the training set
X_test_pca = pca.transform(X_test_scaled)

# Make predictions using the Gradient Boosting model
y_test_pred = gb_model.predict(X_test_pca)

# Create a DataFrame with the PCA components and predicted outcome
columns_pca = [f'PC{i+1}' for i in range(X_test_pca.shape[1])]
X_test_pca_df = pd.DataFrame(data=X_test_pca, columns=columns_pca)
X_test_pca_df['Predicted Consumer disputed?'] = y_test_pred

